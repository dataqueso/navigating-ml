<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.5.0 --> <title>Level 1 Practice | Navigating ML</title> <meta name="generator" content="Jekyll v3.8.5" /> <meta property="og:title" content="Level 1 Practice" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Going from Prebuilt ML Tools to First Custom ML" /> <meta property="og:description" content="Going from Prebuilt ML Tools to First Custom ML" /> <link rel="canonical" href="http://localhost:4000/navigating-ml/level1_practice/" /> <meta property="og:url" content="http://localhost:4000/navigating-ml/level1_practice/" /> <meta property="og:site_name" content="Navigating ML" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2018-11-08T00:00:00-08:00" /> <meta name="twitter:card" content="summary" /> <meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"description":"Going from Prebuilt ML Tools to First Custom ML","@type":"BlogPosting","url":"http://localhost:4000/navigating-ml/level1_practice/","headline":"Level 1 Practice","dateModified":"2018-11-08T00:00:00-08:00","datePublished":"2018-11-08T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/navigating-ml/level1_practice/"},"@context":"http://schema.org"}</script> <!-- End Jekyll SEO tag --> <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"> --> <link rel="stylesheet" href="/navigating-ml/css/main.css"> <link rel="alternate" type="application/rss+xml" title="Navigating ML" href="http://localhost:4000/navigating-ml/feed.xml"> <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> </head> <body> <header class="site-header"> <nav class="navbar navbar-default"> <div class="container-fluid"> <!-- Brand and toggle get grouped for better mobile display --> <div class="navbar-header"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/navigating-ml/">Navigating ML</a> </div> <!-- Collect the nav links, forms, and other content for toggling --> <div class="collapse navbar-collapse " id="bs-example-navbar-collapse-1"> <ul class="nav navbar-nav navbar-right"> <li><a href="/navigating-ml/about/">About</a></li> <li><a href="/navigating-ml/contact/">Contact</a></li> <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Download <span class="caret"></span></a> <ul class="dropdown-menu"> <li><a target="_blank" href="https://github.com/rheartpython/navigating-ml">Project</a></li> <li><a href="https://github.com/rheartpython/navigating-ml/archive/master.zip">Download</a></li> <li role="separator" class="divider"></li> </ul> </li> </ul> </div><!-- /.navbar-collapse --> </div><!-- /.container-fluid --> </nav> </header> <div class="container"> <div class="wrapper"> <div class="row"> <div class="col-md-8"> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <h1 class="post-title" itemprop="name headline">Level 1 Practice</h1> <p class="post-meta"></p> </header> <div class="post-content" itemprop="articleBody"> <h1 id="going-from-prebuilt-ml-tools-to-first-custom-ml">Going from Prebuilt ML Tools to First Custom ML</h1> <p>It is recommended that you have completed the <a href="/navigating-ml/level1_prep">Level 1 Preparation</a>.</p> <p>In this first set of practice problems you’ll learn about basic ML and neural networks, hands-on, with Jupyter notebooks and Python. You’ll be introduced to <code class="highlighter-rouge">scikit-learn</code> and PyTorch as Python packages commonly used in data manipulation and data science.</p> <p>Here and throughout these practice exercises you’ll work with the following image datasets: COCO, Fashion MNIST, the Hymenoptera insect and a few custom ones you create.</p> <h2 id="first-ml-with-custom-vision-service">First ML with Custom Vision Service</h2> <ol> <li> <p>Download the COCO 2017 Val dataset (1 GB) <a href="http://cocodataset.org/#download">here</a> to get a set of real-life images (click on “2017 Val images [5K/1GB]”).</p> </li> <li> <p>Pick 50-100 images to upload, some with people and some without (create a balanced dataset).</p> </li> <li> <p>Build a person/no-person image classifier using Microsoft’s <a href="https://customvision.ai/">https://customvision.ai/</a> (choose “multiclass” classification using the “general” domain) - directions on the <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier">Docs</a> page.</p> </li> <li> <p>Observe performace metrics under the “Performance” tab.</p> </li> </ol> <p><img src="http://nlpforhackers.io/wp-content/uploads/2017/01/Precision-Recall.png" width="50%" /></p> <blockquote> <p>Some defintions. <strong>Precision</strong>: if a tag is precicted by your classifier, how likely is it that it is right? <strong>Recall</strong>: out of the tags that should be classified as right, what percentage did your classifier correctly find?</p> </blockquote> <ol> <li>Square-pad all of the images and build a new classifier under a new project in Custom Vision.</li> </ol> <p>Original:</p> <p><img src="../images/coco_sample.jpg" width="50%" /><br /></p> <p>Square-padded by expanding:</p> <p><img src="../images/coco_sample__pad.jpg" width="50%" /></p> <ul> <li>How do the performance metrics change? Did they get worse or better and why do you think that is?</li> </ul> <h2 id="first-custom-ml-open-source-tools">First Custom ML (Open Source Tools)</h2> <p>For these two problems, it is recommended to go through the code from the original source line by line in whatever fashion you see fit so that you really understand what is going on.</p> <p>TIPS: Place all imports at the top of the notebook. Call the training data something consistent thoughout all of your work (X_train -&gt; training data, y_train -&gt; labels, X_test -&gt; test data…).</p> <h3 id="image-classification-with-classical-ml">Image Classification with Classical ML</h3> <p><img src="../images/fashion_sample.png" alt="fashion dataset sample" /></p> <p>Create a Python program to classify images from Fashion MNIST Dataset (get <a href="https://github.com/zalandoresearch/fashion-mnist">here</a>) leveraging code samples from the Python Data Science Handbook - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Application:-Exploring-Hand-written-Digits">Ref</a>.</p> <p>Refer to Chapter 2 and 3 of the Python Data Science Handbook for information on data manipulation in Python if not already familiar.</p> <p>Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool in the <a href="/navigating-ml/setup">Setup</a> section.</p> <p>Steps:</p> <ul> <li>Visualize a sample of 50-100 images with labels</li> <li>Try fitting a Gaussian naive Bayes model. How does it compare results found in the Handbook for the MNIST Digits datset (a black and white 8x8 pixel dataset of handwritten digits)?</li> </ul> <p>Additionally:</p> <ul> <li>Which fashion item has the best accuracy, which the worst? Use a confusion matrix. Why do you think that is? Is there a way you could imagine improving this model?</li> <li>Normalize the images (in <code class="highlighter-rouge">sklearn</code>) and check the accuracy of the model(s) again. Did it improve or worsen?</li> <li>Try a different model - SVM or Random Forest</li> </ul> <h3 id="image-classification-with-basic-neural-nets">Image Classification with Basic Neural Nets</h3> <p>The purpose of the Basic Neural Nets exercises are to familiarize you with how a simple artificial neuron works all from the ground-up - this knowledge will serve you well. See <a href="/navigating-ml/level1_prep">Level 1 Preparation</a> for more information.</p> <ol> <li> <p>Adapt a from-scratch Perceptron as in this <a href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch02/ch02.ipynb">Jupyter notebook</a> to train and test on the Fashion MNIST dataset.</p> <ul> <li>Does the model converge or not (plot the training and validation error)?</li> </ul> </li> <li> <p>Adapt a from-scratch Multilayer Perceptron (MLP) as in this <a href="https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch12/ch12.ipynb">Jupyter notebook</a></p> <ul> <li>Try it again with the <code class="highlighter-rouge">scikit-learn</code> MLP class.</li> <li>Does the model converge now? What accuracy does the model achieve?</li> </ul> </li> </ol> <h3 id="object-detection-with-histogram-of-oriented-gradients">Object Detection with Histogram of Oriented Gradients</h3> <p>Create a Python program to detect bear faces (perhaps you’re builing a bear watch app for safety in the woods) by leveraging code samples from this <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.14-image-features.html" target="_blank">Python Data Science Handbook notebook</a>.</p> <p><img src="../images/bear_face_hog.png" alt="bear face with hog" /></p> <ul> <li>Collect 50-100 images of bear faces from the web and square-pad them as done for the COCO images above. In addition, resize them to the same shape (228x228 for example). Observe, that in the code sample, the shape of the final image data for training will be (100, 228, 228) if 100 samples are collected. These constitute the “positive” training samples.</li> </ul> <p>An example of the image pre-processing (padding is up to you):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_array</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Get image files
</span><span class="n">img_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s">'../../data/bears_pad/*.*'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">img_files</span><span class="p">:</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="c1"># Resize to uniform size
</span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">228</span><span class="p">,</span> <span class="mi">228</span><span class="p">))</span>
    <span class="c1"># Convert to only grayscale in case of an alpha channel
</span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s">'L'</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">data_array</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>

<span class="c1"># Convert collection to numpy array
</span><span class="n">positive_patches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data_array</span><span class="p">)</span>
<span class="n">positive_patches</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div></div> <p>The rest of the steps are outlined as follows (as described in the Handbook):</p> <ul> <li>Obtain a set of image thumbnails of non-faces to constitute “negative” training samples.</li> <li>Extract HOG features from these training samples.</li> <li>Train a linear SVM classifier on these samples.</li> <li>For an “unknown” image, pass a sliding window across the image, using the model to evaluate whether that window contains a face or not.</li> <li>If detections overlap, combine them into a single window.</li> </ul> <p>Additionally:</p> <ul> <li>What other confounding factors are there for images other than illumination, you think?</li> <li>Plot the original image along with the <code class="highlighter-rouge">skimage.rgb2gray</code> version and the HOG representation. See how this works in <code class="highlighter-rouge">matplotlib</code>. What does <code class="highlighter-rouge">skimage.rgb2gray</code> actually do?</li> <li>Try out the model on the entire test image. What do you find out?</li> </ul> <p>A cursory result might be (after varying window sizes): <img src="../images/bear_with_bboxes2.png" alt="model prediction" /></p> <ul> <li>Try using sliding windows with a variety of sizes (and aspect ratios). What do you find out?</li> <li>Augment the data to expand the training and test datasets (e.g. use a library like <code class="highlighter-rouge">imgaug</code> to left-right flip, blur, contrast normalize, etc.) and retrain and test. How does the performance change and why is that?</li> <li><strong>Extra credit</strong>: Implement Non-Maximum Suppression in Python to find the single best bounding box of a group of bounding boxes as are found above. Apply this to the test image.</li> </ul> <h2 id="additional-help">Additional Help</h2> <ul> <li>StackOverflow with <code class="highlighter-rouge">sklearn</code>, <code class="highlighter-rouge">jupyter</code></li> <li>For Custom Vision you can email customvisionteam@microsoft.com.</li> </ul> </div> </article> <div class="row"> <div id="disqus_thread"></div> <script defer> (function() { var d = document, s = d.createElement('script'); s.src = '//navigating-ml.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> </div> <div class="row"> <ul class="pager"> <li><a class="next" href="/navigating-ml/level1_prep/">&laquo; Level 1 Preparation</a></li> <li><a class="previous" href="/navigating-ml/level2_prep/">Level 2 Preparation &raquo;</a></li> </ul> </div> </div> <div class="col-md-4 mt20"> <div class="post-img"> <img width="600" src="/navigating-ml/images/third.jpg" alt="Level 1 Practice"> </div> <div class="mt10 recent"> <h2>Related</h2> <ul> <li> <p><a href="/navigating-ml/setup/">Data Science Setup</a></p> </li> <li> <p><a href="/navigating-ml/level1_prep/">Level 1 Preparation</a></p> </li> <li> <p><a href="/navigating-ml/level2_prep/">Level 2 Preparation</a></p> </li> </ul> </div> <br> </div> </div> </div> </div> <footer> <div class="container"> <div class="row p20"> <div class="col-md-4 text-center mt25">All rights reserved by <a target="_blank" href="">micheleen harris</a></div> <div class="col-md-4 text-center mt25" > </div> <div class="col-md-4 text-center mt25"> <a target="_blank" href="http://twitter.com/@rheartpython"><li class="social twitter"><i class="fa fa-twitter-square"></i></li></a> <a target="_blank" href="http://github.com/rheartpython"><li class="social github"><i class="fa fa-github-square"></i></li></a> </div> </div> </div> </footer> <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script> <script src="/navigating-ml/js/bootstrap.min.js"></script> <!-- Google Analytics Tracking code --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-129282757-1', 'auto'); ga('send', 'pageview'); </script> </body> </html>
