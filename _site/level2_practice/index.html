<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.5.0 --> <title>Level 2 Practice | Navigating ML</title> <meta name="generator" content="Jekyll v3.8.5" /> <meta property="og:title" content="Level 2 Practice" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Intermediate Practice with Deep Learning" /> <meta property="og:description" content="Intermediate Practice with Deep Learning" /> <link rel="canonical" href="http://localhost:4000/navigating-ml/level2_practice/" /> <meta property="og:url" content="http://localhost:4000/navigating-ml/level2_practice/" /> <meta property="og:site_name" content="Navigating ML" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2018-11-05T00:00:00-08:00" /> <meta name="twitter:card" content="summary" /> <meta name="twitter:site" content="@" /> <script type="application/ld+json"> {"description":"Intermediate Practice with Deep Learning","@type":"BlogPosting","url":"http://localhost:4000/navigating-ml/level2_practice/","headline":"Level 2 Practice","dateModified":"2018-11-05T00:00:00-08:00","datePublished":"2018-11-05T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/navigating-ml/level2_practice/"},"@context":"http://schema.org"}</script> <!-- End Jekyll SEO tag --> <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"> --> <link rel="stylesheet" href="/navigating-ml/css/main.css"> <link rel="alternate" type="application/rss+xml" title="Navigating ML" href="http://localhost:4000/navigating-ml/feed.xml"> <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> </head> <body> <header class="site-header"> <nav class="navbar navbar-default"> <div class="container-fluid"> <!-- Brand and toggle get grouped for better mobile display --> <div class="navbar-header"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/navigating-ml/">Navigating ML</a> </div> <!-- Collect the nav links, forms, and other content for toggling --> <div class="collapse navbar-collapse " id="bs-example-navbar-collapse-1"> <ul class="nav navbar-nav navbar-right"> <li><a href="/navigating-ml/about/">About</a></li> <li><a href="/navigating-ml/contact/">Contact</a></li> <li class="dropdown"> <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Download <span class="caret"></span></a> <ul class="dropdown-menu"> <li><a target="_blank" href="https://github.com/rheartpython/navigating-ml">Project</a></li> <li><a href="https://github.com/rheartpython/navigating-ml/archive/master.zip">Download</a></li> <li role="separator" class="divider"></li> </ul> </li> </ul> </div><!-- /.navbar-collapse --> </div><!-- /.container-fluid --> </nav> </header> <div class="container"> <div class="wrapper"> <div class="row"> <div class="col-md-8"> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <h1 class="post-title" itemprop="name headline">Level 2 Practice</h1> <p class="post-meta"></p> </header> <div class="post-content" itemprop="articleBody"> <h1 id="intermediate-practice-with-deep-learning">Intermediate Practice with Deep Learning</h1> <p>It is recommended that you have completed the <a href="/navigating-ml/level2_prep">Level 2 Preparation</a>.</p> <p>In this intermediate set of problems, you’ll apply what you’ve learned in the Level 2 Preparation section. You’ll utilize your bear and COCO dataset with an MLP and CNN in PyTorch, including and introduction to transfer learning.</p> <h2 id="adapt-a-multilayer-perceptron-and-cnn">Adapt a Multilayer Perceptron and CNN</h2> <h3 id="image-classification">Image Classification</h3> <p>Instructions to practice image classification with PyTorch</p> <h4 id="setup">Setup</h4> <p>Let’s dive into some data and code. Open a Jupyter session or log into the Jupyter system</p> <ul> <li>In a code cell <code class="highlighter-rouge">! git clone https://github.com/rasbt/deep-learning-book.git</code></li> <li>Navigate to this directory: <code class="highlighter-rouge">/code/model_zoo/pytorch_ipynb</code> where we will operate.</li> </ul> <h4 id="data">Data</h4> <p>We will work with your square-padded bears dataset from Level 1 (if you do not have these, go to Level 1 and set up the datasets) and a similar number of the square-padded COCO images (ones that are not images of a bear, of course - remove any that are here because there are some sneaky bears in COCO).</p> <ul> <li>Set up the following data folder structure where the notebooks live: <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  data/train/bear
  data/train/not_bear
  data/test/bear
  data/test/not_bear
</code></pre></div> </div> </li> <li>Place all, but 5 of the square-padded images of bears, into <code class="highlighter-rouge">data/train/bear</code>. Place all but 5 square-padded images of non-bear from a subset of COCO, into <code class="highlighter-rouge">data/train/not_bear</code>.</li> <li>Place the remaining bear images into the <code class="highlighter-rouge">data/test/bear</code> and likewise with the non-bear images, but into <code class="highlighter-rouge">data/test/not_bear</code></li> </ul> <h4 id="train-a-multi-layer-perceptron">Train a Multi-Layer Perceptron</h4> <ul> <li>Open the <code class="highlighter-rouge">multilayer-perceptron.ipynb</code> notebook</li> <li>Modify the notebook in the right places to work with your bear dataset - check out the usage of torchvisions <code class="highlighter-rouge">datasets.ImageFolder</code> (<a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#load-data" target="_blank">Example</a>) for easily creating a PyTorch-compatible dataset based on folder structures upon which the data loaders can work (the folder structures serve as the labels!).</li> <li>Make sure to add <code class="highlighter-rouge">transforms</code> to “Resize” the input. Try out other transforms as well as you go along to see if there are improvements in the accuracy.</li> </ul> <blockquote> <p>Most deep learning frameworks have their own dataset formats - often several. PyTorch has many standard readers for data as well as an object oriented guideline to create custom datasets that work with the PyTorch data loaders. It can thus be very flexible.</p> </blockquote> <ul> <li>Look at the mathematical notations in the notebook in the model definition to figure out the final FC layer size - you will see errors otherwise.</li> <li>A few other hyperparameters may need to be looked at.</li> </ul> <h4 id="train-a-cnn-vgg16">Train a CNN (VGG16)</h4> <ul> <li>Do the same as above, but with the <code class="highlighter-rouge">convnet-vgg16.ipynb</code>.</li> </ul> <p>VGG16 has the following architecture (VGGNet was the runner-up of the ILSVRC 2014 competition, a.k.a., the ImageNet challenge).</p> <p><img src="https://cdn-images-1.medium.com/max/1600/0*V1muWIDnPVwZUuEv.png" alt="vgg16" /></p> <p>Add the following transform to the <code class="highlighter-rouge">train</code> and <code class="highlighter-rouge">test</code> dataset instantiation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
                                                                  <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                                                  <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                                                     <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])])</span>
</code></pre></div></div> <ul> <li>Why are we resizing to 32x32 pixels?</li> <li>Wny is the test accuracy so low in the above cases?</li> <li>How would you modify the network in the case of 228x228 3-channel input (say you Resize to 228)?</li> </ul> <h2 id="transfer-learning-with-pytorch">Transfer Learning with PyTorch</h2> <p><img src="../images/tl_bear_not_bear.png" alt="bear not bear" /></p> <p>Transfer learning can address the issue of small datasets by starting with pre-trained weights, weights that get us closer to recognizing objects that we are wishing to classify, instead of starting with random weights on our parameters.</p> <blockquote> <p>Note, if your objects differ significantly from the objects upon which the pre-trained network was originally trained (usually ImageNet or COCO), some more data may be needed as well as potentially unfreezing more layers for fine-tuning.</p> </blockquote> <p>Modify <a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" target="_blank">this</a> PyTorch tutorial to work with VGG16 and the bear/not_bear dataset you have come to enjoy. You may need to take a look at the layers of VGG16 found in the following, to decide how to modify the last layer for different output size (i.e. different number of classes).</p> <p>Note, the <code class="highlighter-rouge">model_object.classifier</code> is actually a sequential list of fully connected layers (see diagram above). Also, to see this classifier defined, you can take a look at:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_object</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_modules</span>
</code></pre></div></div> <p>Additionally, defining a new layer will have a grad function and gradients enabled by default for backprop. What must you do to freeze the layers before the last layer so that you are only fine-tuning on that last layer?</p> <p>Once you’ve worked out the updates, train the model on your bear/no bear data.</p> <ul> <li>How much has the result improved?</li> <li>If you wished to “unfreeze” more than the last layer, how would you do so?</li> <li>If you had 3 classes instead of 2, how would you modify the network architecture?</li> </ul> <h2 id="additional-help">Additional Help</h2> <ul> <li>PyTorch forums - <a href="https://discuss.pytorch.org/">Ref</a></li> <li>StackOverflow with <code class="highlighter-rouge">pytorch</code> tag</li> </ul> </div> </article> <div class="row"> <div id="disqus_thread"></div> <script defer> (function() { var d = document, s = d.createElement('script'); s.src = '//navigating-ml.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> </div> <div class="row"> <ul class="pager"> <li><a class="next" href="/navigating-ml/level2_prep/">&laquo; Level 2 Preparation</a></li> <li><a class="previous" href="/navigating-ml/level3_prep/">Level 3 Preparation &raquo;</a></li> </ul> </div> </div> <div class="col-md-4 mt20"> <div class="post-img"> <img width="600" src="/navigating-ml/images/sixth.jpg" alt="Level 2 Practice"> </div> <div class="mt10 recent"> <h2>Related</h2> <ul> <li> <p><a href="/navigating-ml/setup/">Data Science Setup</a></p> </li> <li> <p><a href="/navigating-ml/level1_prep/">Level 1 Preparation</a></p> </li> <li> <p><a href="/navigating-ml/level1_practice/">Level 1 Practice</a></p> </li> </ul> </div> <br> </div> </div> </div> </div> <footer> <div class="container"> <div class="row p20"> <div class="col-md-4 text-center mt25">All rights reserved by <a target="_blank" href="">micheleen harris</a></div> <div class="col-md-4 text-center mt25" > </div> <div class="col-md-4 text-center mt25"> <a target="_blank" href="http://twitter.com/@rheartpython"><li class="social twitter"><i class="fa fa-twitter-square"></i></li></a> <a target="_blank" href="http://github.com/rheartpython"><li class="social github"><i class="fa fa-github-square"></i></li></a> </div> </div> </div> </footer> <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script> <script src="/navigating-ml/js/bootstrap.min.js"></script> <!-- Google Analytics Tracking code --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-129282757-1', 'auto'); ga('send', 'pageview'); </script> </body> </html>
